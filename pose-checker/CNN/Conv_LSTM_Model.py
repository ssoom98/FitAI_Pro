import os
import numpy as np
import json
import cv2
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
import tensorflow as tf
from tensorflow.keras.applications import NASNetMobile, ResNet101, EfficientNetB3, EfficientNetB7
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Input, ConvLSTM2D, TimeDistributed, BatchNormalization,
    Conv2D, Dense, Flatten, GlobalAveragePooling2D, 
    GlobalAveragePooling1D, Dropout, Reshape
)
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau
import seaborn as sns
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from datetime import datetime
from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score


class DatasetLoader:
    """
    ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ í´ë˜ìŠ¤ (Train/Test ìë™ ë¶„í•  í¬í•¨)
    """
    def __init__(self, base_dir, img_base_dir, img_size=(64, 64), test_split=0.2):
        """
        ì´ˆê¸°í™”
        :param base_dir: JSON ë°ì´í„°ì…‹ì´ ìˆëŠ” í´ë”
        :param img_base_dir: ì´ë¯¸ì§€ íŒŒì¼ì´ ì €ì¥ëœ í´ë”
        :param img_size: ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸ê°’: 64x64)
        :param test_split: Train/Test ë°ì´í„° ë¶„í•  ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2, ì¦‰ 80% Train / 20% Test)
        """
        self.base_dir = base_dir
        self.img_base_dir = img_base_dir
        self.img_size = img_size
        self.test_split = test_split  # Train/Test ë¹„ìœ¨ ì„¤ì •

    def stratified_sampling_and_split(self, df, category_column, sample_size=None):
        """
        ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ì§€ì •ëœ ê°œìˆ˜ë§Œí¼ ì¸µí™”ì¶”ì¶œ (ìë™ ìƒ˜í”Œë§ ê°€ëŠ¥)
        :param df: ì…ë ¥ ë°ì´í„°í”„ë ˆì„
        :param category_column: ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ëª… (ì˜ˆ: 'type')
        :param sample_size: ìƒ˜í”Œë§í•  ê°œìˆ˜ (Noneì´ë©´ ì „ì²´ ì‚¬ìš©)
        """
        sampled_dfs = []
        for category in df[category_column].unique():
            category_df = df[df[category_column] == category]
            
            # sample_sizeê°€ Noneì´ë©´ ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©
            if sample_size is None:
                sampled_df = category_df
            else:
                sampled_df = category_df.sample(n=min(sample_size, len(category_df)))
            
            sampled_dfs.append(sampled_df)
        
        return pd.concat(sampled_dfs).sample(frac=1).reset_index(drop=True)
    
    def stratified_sampling_and_split_categorys(self, df, category_1, category_2, sample_size=None):
        
        """
        category_1 ë‚´ì—ì„œ category_2ì˜ ì¤‘ë³µ ì—†ì´ ìƒ˜í”Œë§í•˜ê³ , ê° category_1ì—ì„œ sample_sizeë§Œí¼ ë°ì´í„° ì„ íƒ

        :param df: ì…ë ¥ ë°ì´í„°í”„ë ˆì„
        :param category_1: ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ëª… (ì˜ˆ: 'ëŒ€ë¶„ë¥˜')
        :param category_2: ë‘ ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ëª… (ì˜ˆ: 'ì†Œë¶„ë¥˜')
        :param sample_size: category_1ë³„ ìƒ˜í”Œë§í•  ê°œìˆ˜ (Noneì´ë©´ ì „ì²´ ì‚¬ìš©)
        :return: ìƒ˜í”Œë§ëœ ë°ì´í„°í”„ë ˆì„
        """
        sampled_dfs = []
        total_samples = 0  # ì´ ìƒ˜í”Œ ê°œìˆ˜ ì¶”ì 

        print(f"{category_1} ê¸°ì¤€ìœ¼ë¡œ {category_2} ìƒ˜í”Œë§ ì‹œì‘")

        # ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬(`category_1`)ë³„ ê·¸ë£¹í™”
        for cat1_value in df[category_1].unique():
            cat1_df = df[df[category_1] == cat1_value]
            print(f" {category_1}: {cat1_value} ì²˜ë¦¬ ì¤‘")

            # `category_2`ì˜ ì¤‘ë³µ ì œê±°
            unique_category_2 = cat1_df[category_2].unique()

            # category_2 ì¤‘ë³µ ì—†ì´ category_1 ë³„ sample_size ë§Œí¼ ìƒ˜í”Œë§
            num_samples = min(sample_size, len(unique_category_2)) if sample_size else len(unique_category_2)

            # category_2 ëœë¤ ìƒ˜í”Œë§ (ì¤‘ë³µ ë°©ì§€)
            selected_category_2 = np.random.choice(unique_category_2, size=num_samples, replace=False)

            # ì„ íƒëœ category_2ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„° ì¤‘ ëœë¤ sample_size ìƒ˜í”Œë§
            sampled_df = cat1_df[cat1_df[category_2].isin(selected_category_2)].sample(n=num_samples)

            sampled_dfs.append(sampled_df)
            total_samples += len(sampled_df)

            print(f" - {category_2} ì¤‘ë³µ ì—†ì´ {num_samples}ê°œ ìƒ˜í”Œë§ ì™„ë£Œ")

        # ğŸ”¹ ìµœì¢… ë°ì´í„°í”„ë ˆì„ ìƒì„± (ì…”í”Œ)
        final_df = pd.concat(sampled_dfs).sample(frac=1).reset_index(drop=True)

        print(f"ìµœì¢… ìƒ˜í”Œë§ ì™„ë£Œ! ì´ {total_samples}ê°œì˜ ë°ì´í„°ê°€ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")

        return final_df


    def load_images(self, folder_image_paths, categories):
        """
        íŠ¹ì • íŒŒì¼ ê·¸ë£¹ (folder_image_path ê¸°ì¤€)ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë¬¶ì–´ 5D NumPy ë°°ì—´ë¡œ ë³€í™˜
        """
        category_mapping = {
            'ë°”ë²¨/ë¤ë²¨': 'Barbell_Dumbbell/',
            'ë§¨ëª¸ ìš´ë™': 'Bodyweight/',
            'ê¸°êµ¬': 'Equipment/'
        }

        image_groups = []
        max_images_per_group = 0
        all_groups = []
        category_list = []

        for folder_image_path, category in zip(folder_image_paths, categories):
            category_dir = category_mapping.get(category)
            folder_image_path = folder_image_path.replace("/", "@")
            img_list = sorted(os.listdir(self.img_base_dir + category_dir))
            img_paths = [img for img in img_list if folder_image_path in img]
            image_group = []
            category_added = False
            for img_path in img_paths:
                img = cv2.imread(self.img_base_dir + category_dir + img_path)
                if img is not None:
                    img = cv2.resize(img, self.img_size)
                    image_group.append(img)
                    if not category_added:
                        category_list.append(category)
                        category_added = True
                    print(img_path, 'ë¡œë“œ ì™„ë£Œ')
                else:
                    print(f"Error loading: {img_path}")

            if image_group:
                max_images_per_group = max(max_images_per_group, len(image_group))
                all_groups.append(image_group)
            
        
        # Zero Padding (sahpeì„ ì¼ì •í•˜ê²Œ ìœ ì§€ì§€)
        for group in all_groups:
            while len(group) < max_images_per_group:
                group.append(np.zeros((self.img_size[0], self.img_size[1], 3), dtype=np.float32))

            image_groups.append(np.array(group, dtype=np.float32) / 255.0)

        return np.array(image_groups, dtype=np.float32), np.array(category_list)
    

    def sub_model_load_images(self, folder_image_paths, categories, return_categories):
        """
        íŠ¹ì • íŒŒì¼ ê·¸ë£¹ (folder_image_path ê¸°ì¤€)ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë¬¶ì–´ 5D NumPy ë°°ì—´ë¡œ ë³€í™˜
        """
        category_mapping = {
            'ë°”ë²¨/ë¤ë²¨': 'Barbell_Dumbbell/',
            'ë§¨ëª¸ ìš´ë™': 'Bodyweight/',
            'ê¸°êµ¬': 'Equipment/'
        }
        
        image_groups = []
        max_images_per_group = 0
        all_groups = []
        category_list = []

        # folder_image_pathsì˜ indexì™€ í•¨ê»˜ ë°˜ë³µ
        for idx, (folder_image_path, category) in enumerate(zip(folder_image_paths, categories)):
            category_dir = category_mapping.get(category)
            folder_image_path = folder_image_path.replace("/", "@")

            # í•´ë‹¹ ë””ë ‰í† ë¦¬ì˜ ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            img_list = sorted(os.listdir(self.img_base_dir + category_dir))
            img_paths = [img for img in img_list if folder_image_path in img]

            image_group = []

            for img_path in img_paths:
                img = cv2.imread(self.img_base_dir + category_dir + img_path)
                if img is not None:
                    img = cv2.resize(img, self.img_size)
                    image_group.append(img)
                    print(img_path, 'ë¡œë“œ ì™„ë£Œ')
                else:
                    print(f"Error loading: {img_path}")

            if image_group:
                max_images_per_group = max(max_images_per_group, len(image_group))
                all_groups.append(image_group)

                # return_categoriesì—ì„œ í˜„ì¬ indexì— í•´ë‹¹í•˜ëŠ” ê°’ ì¶”ê°€
                if idx in return_categories.index:
                    category_list.append(return_categories.loc[idx])

        # Zero Padding (shapeì„ ì¼ì •í•˜ê²Œ ìœ ì§€)
        for group in all_groups:
            while len(group) < max_images_per_group:
                group.append(np.zeros((self.img_size[0], self.img_size[1], 3), dtype=np.float32))

            image_groups.append(np.array(group, dtype=np.float32) / 255.0)

        return np.array(image_groups, dtype=np.float32), np.array(category_list)



    def split_data(self, X_data, labels_array, save_mapping=True, mapping_filename="label_mapping.json"):
        """
        5D NumPy ë°°ì—´(X)ê³¼ 1ì°¨ì› NumPy ë¬¸ìì—´ ë°°ì—´(Y)ì„ ì…ë ¥ë°›ì•„ Train/Test ë°ì´í„° ë¶„í•  (ì´ë¯¸ì§€ ë¡œë“œ ì œê±°)
        
        :param X_data: 5D NumPy ë°°ì—´ (ì´ë¯¸ì§€ ë°ì´í„°)
        :param labels_array: 1ì°¨ì› NumPy ë°°ì—´ (ë¬¸ìì—´ ë¼ë²¨)
        :param save_mapping: jsoníŒŒì¼ë¡œ ì €ì¥ì„ ì§„í–‰í• ì§€ ì—¬ë¶€ (bool)
        :param mapping_filename: ë¼ë²¨ì¸ì½”ë”ì˜ ì •ë³´ë¥¼ jsoníŒŒì¼ë¡œ ì €ì¥í• ë•Œ íŒŒì¼ì´ë¦„
        :return: train_X, train_Y, test_X, test_Y, label_mapping
        """
        # Train/Test ë°ì´í„° ë¶„í• 
        train_X, test_X, train_Y_raw, test_Y_raw = train_test_split(
            X_data, labels_array, test_size=self.test_split, stratify=labels_array
        )

        # ë¼ë²¨ ì¸ì½”ë”© (ë¬¸ìí˜• â†’ ìˆ«ìí˜•)
        label_encoder = LabelEncoder()
        train_Y_encoded = label_encoder.fit_transform(train_Y_raw)
        test_Y_encoded = label_encoder.transform(test_Y_raw)

        # ì›-í•« ì¸ì½”ë”© (ìˆ«ìí˜• â†’ ì›-í•« ë²¡í„°)
        train_Y = to_categorical(train_Y_encoded)
        test_Y = to_categorical(test_Y_encoded)

        # ë¼ë²¨ ì¸ì½”ë”© ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        label_mapping = {class_name: int(label_id) for class_name, label_id in zip(label_encoder.classes_, range(len(label_encoder.classes_)))}

        print(f"Train X {train_X.shape}, Train Y {train_Y.shape}, Test X {test_X.shape}, Test Y {test_Y.shape}")
        print(f"ë¼ë²¨ ì¸ì½”ë”© ë§¤í•‘: {label_mapping}")

        def save_label_mapping(label_mapping, filename="label_mapping.json"):
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(label_mapping, f, indent=4, ensure_ascii=False)

        if save_mapping:
            if "/" in mapping_filename:
                safe_filename = mapping_filename.replace("/", "_")
            save_label_mapping(label_mapping, filename=safe_filename)

        return train_X, train_Y, test_X, test_Y, label_mapping




class ConvLSTM_NasNet_Model:
    """
    ConvLSTM + NASNetMobile ëª¨ë¸ í´ë˜ìŠ¤
    """
    def __init__(self, input_shape=(None, 64, 64, 3), num_classes=3):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model = self.build_model()

    def build_model(self):
        video_input = Input(shape=self.input_shape)
        x = ConvLSTM2D(filters=64, kernel_size=(3, 3), padding="same", return_sequences=True, activation="relu")(video_input)
        x = BatchNormalization()(x)

        # ConvLSTM â†’ NASNetMobile ì—°ê²°ì„ ìœ„í•´ ì±„ë„ ë³€í™˜
        x = TimeDistributed(Conv2D(3, (1, 1), activation="relu"))(x)

        # NASNetMobile ë¶ˆëŸ¬ì˜¤ê¸° (ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©)
        base_model = NASNetMobile(weights="imagenet", include_top=False, input_shape=(64, 64, 3))
        base_model.trainable = False  # ì´ˆê¸° ê°€ì¤‘ì¹˜ ë™ê²°

        for layer in base_model.layers[-20:]:  
            layer.trainable = True  # ë§ˆì§€ë§‰ 20ê°œ ë ˆì´ì–´ë§Œ í•™ìŠµ ê°€ëŠ¥

        # TimeDistributedë¡œ NASNet ì ìš©
        x = TimeDistributed(base_model)(x)
        x = BatchNormalization()(x)
        x = TimeDistributed(GlobalAveragePooling2D())(x)

        # ì°¨ì› ì¶•ì†Œ
        x = GlobalAveragePooling1D()(x)

        # Fully Connected Layer
        x = Flatten()(x)
        x = Dense(512, activation="relu", kernel_regularizer=l2(0.01))(x)
        x = Dropout(0.3)(x)
        x = Dense(256, activation="relu", kernel_regularizer=l2(0.01))(x)
        x = Dropout(0.3)(x)
        x = Dense(128, activation="relu", kernel_regularizer=l2(0.01))(x)
        x = Dropout(0.3)(x)
        x = Dense(self.num_classes, activation="softmax")(x)

        model = Model(inputs=video_input, outputs=x)
        model.compile(optimizer='adam',
                      loss="categorical_crossentropy",
                      metrics=["accuracy"])
        return model
    
class ConvLSTM_ResNet_Model:
    """
    ConvLSTM + ResNet101 ëª¨ë¸ í´ë˜ìŠ¤
    """
    def __init__(self, input_shape=(None, 64, 64, 3), num_classes=3):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model = self.build_model()

    def build_model(self):
        video_input = Input(shape=self.input_shape)
        x = ConvLSTM2D(filters=128, kernel_size=(5, 5), padding="same", return_sequences=True, activation="relu")(video_input)
        x = BatchNormalization()(x)

        # ConvLSTM â†’ ResNet101 ì—°ê²°ì„ ìœ„í•´ ì±„ë„ ë³€í™˜
        x = TimeDistributed(Conv2D(3, (1, 1), activation="relu"))(x)

        # ResNet101 ë¶ˆëŸ¬ì˜¤ê¸° (ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©)
        base_model = ResNet101(weights="imagenet", include_top=False, input_shape=(64, 64, 3))
        base_model.trainable = False  # ì´ˆê¸° ê°€ì¤‘ì¹˜ ë™ê²°

        for layer in base_model.layers[-30:]:  
            layer.trainable = True  # ë§ˆì§€ë§‰ 20ê°œ ë ˆì´ì–´ë§Œ í•™ìŠµ ê°€ëŠ¥

        # TimeDistributedë¡œ ResNet ì ìš©
        x = TimeDistributed(base_model)(x)
        x = BatchNormalization()(x)
        x = TimeDistributed(GlobalAveragePooling2D())(x)

        # ì°¨ì› ì¶•ì†Œ
        x = GlobalAveragePooling1D()(x)

        # Fully Connected Layer
        x = Flatten()(x)
        x = Dense(512, activation="relu", kernel_regularizer=l2(0.01))(x)
        x = Dropout(0.3)(x)
        x = Dense(256, activation="relu", kernel_regularizer=l2(0.01))(x)
        x = Dropout(0.3)(x)
        x = Dense(128, activation="relu", kernel_regularizer=l2(0.01))(x)
        x = Dropout(0.2)(x)
        x = Dense(self.num_classes, activation="softmax")(x)

        model = Model(inputs=video_input, outputs=x)
        model.compile(optimizer='adam',
                      loss="categorical_crossentropy",
                      metrics=["accuracy"])
        return model

class ConvLSTM_EfficientNetB7_Model:
    """
    ConvLSTM + EfficientNetB7 ëª¨ë¸ í´ë˜ìŠ¤
    """
    def __init__(self, input_shape=(None, 64, 64, 3), num_classes=3):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model = self.build_model()

    def build_model(self):
        video_input = Input(shape=self.input_shape)
        x = ConvLSTM2D(filters=128, kernel_size=(5, 5), padding="same", return_sequences=True, activation="relu")(video_input)
        x = BatchNormalization()(x)

        # ConvLSTM â†’ ResNet101 ì—°ê²°ì„ ìœ„í•´ ì±„ë„ ë³€í™˜
        x = TimeDistributed(Conv2D(3, (1, 1), activation="relu"))(x)

        # ResNet101 ë¶ˆëŸ¬ì˜¤ê¸° (ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©)
        base_model = EfficientNetB7(weights="imagenet", include_top=False, input_shape=(64, 64, 3))
        base_model.trainable = False  # ì´ˆê¸° ê°€ì¤‘ì¹˜ ë™ê²°

        for layer in base_model.layers[-30:]:  
            layer.trainable = True  # ë§ˆì§€ë§‰ 20ê°œ ë ˆì´ì–´ë§Œ í•™ìŠµ ê°€ëŠ¥

        # TimeDistributedë¡œ ResNet ì ìš©
        x = TimeDistributed(base_model)(x)
        x = BatchNormalization()(x)
        x = TimeDistributed(GlobalAveragePooling2D())(x)

        # ì°¨ì› ì¶•ì†Œ
        x = GlobalAveragePooling1D()(x)

        # Fully Connected Layer
        x = Flatten()(x)
        x = Dense(512, activation="relu", kernel_regularizer=l2(0.01))(x)
        x = Dropout(0.3)(x)
        x = Dense(256, activation="relu", kernel_regularizer=l2(0.01))(x)
        x = Dropout(0.3)(x)
        x = Dense(128, activation="relu", kernel_regularizer=l2(0.01))(x)
        x = Dropout(0.2)(x)
        x = Dense(self.num_classes, activation="softmax")(x)

        model = Model(inputs=video_input, outputs=x)
        model.compile(optimizer='adam',
                      loss="categorical_crossentropy",
                      metrics=["accuracy"])
        return model

# class ConvLSTM_EfficientNetB3_Model:
#     """
#     ConvLSTM + EfficientNetB3 ëª¨ë¸ í´ë˜ìŠ¤
#     """
#     def __init__(self, input_shape=(None, 64, 64, 3), num_classes=3):
#         self.input_shape = input_shape
#         self.num_classes = num_classes
#         self.model = self.build_model()

#     def build_model(self):
#         video_input = Input(shape=self.input_shape)
#         x = ConvLSTM2D(filters=64, kernel_size=(3, 3), padding="same", return_sequences=True, activation="relu")(video_input)
#         x = BatchNormalization()(x)

#         x = ConvLSTM2D(filters=128, kernel_size=(3, 3), padding="same", return_sequences=True, activation="relu")(x)
#         x = BatchNormalization()(x)

#         x = ConvLSTM2D(filters=256, kernel_size=(3, 3), padding="same", return_sequences=False, activation="relu")(x)
#         x = BatchNormalization()(x)

#         x = Reshape((1, 64, 64, 256))(x)
#         # ConvLSTM â†’ EfficientNetB3 ì—°ê²°ì„ ìœ„í•´ ì±„ë„ ë³€í™˜
#         x = TimeDistributed(Conv2D(3, (1, 1), activation="relu"))(x)

#         # NASNetMobile ë¶ˆëŸ¬ì˜¤ê¸° (ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©)
#         base_model = EfficientNetB3(weights="imagenet", include_top=False, input_shape=(64, 64, 3))
#         base_model.trainable = False  # ì´ˆê¸° ê°€ì¤‘ì¹˜ ë™ê²°

#         for layer in base_model.layers[-20:]:  
#             layer.trainable = True  # ë§ˆì§€ë§‰ 20ê°œ ë ˆì´ì–´ë§Œ í•™ìŠµ ê°€ëŠ¥

#         # TimeDistributedë¡œ NASNet ì ìš©
#         x = TimeDistributed(base_model)(x)
#         x = BatchNormalization()(x)
#         x = TimeDistributed(GlobalAveragePooling2D())(x)

#         # ì°¨ì› ì¶•ì†Œ
#         x = GlobalAveragePooling1D()(x)

#         # Fully Connected Layer
#         x = Flatten()(x)
#         x = Dense(512, activation="relu", kernel_regularizer=l2(0.01))(x)
#         x = Dropout(0.3)(x)
#         x = Dense(256, activation="relu", kernel_regularizer=l2(0.01))(x)
#         x = Dropout(0.3)(x)
#         x = Dense(128, activation="relu", kernel_regularizer=l2(0.01))(x)
#         x = Dropout(0.3)(x)
#         x = Dense(self.num_classes, activation="softmax")(x)

#         model = Model(inputs=video_input, outputs=x)
#         model.compile(optimizer='adam',
#                       loss="categorical_crossentropy",
#                       metrics=["accuracy"])
#         return model

def build_model(self):
    video_input = Input(shape=self.input_shape)
    
    # ConvLSTM2D ìŠ¤íƒ ì ìš©
    x = ConvLSTM2D(filters=64, kernel_size=(3, 3), padding="same", return_sequences=True, activation="relu")(video_input)
    x = BatchNormalization()(x)

    x = ConvLSTM2D(filters=128, kernel_size=(3, 3), padding="same", return_sequences=True, activation="relu")(x)
    x = BatchNormalization()(x)

    x = ConvLSTM2D(filters=256, kernel_size=(3, 3), padding="same", return_sequences=False, activation="relu")(x)
    x = BatchNormalization()(x)

    # ConvLSTM â†’ EfficientNetB3 ì—°ê²°ì„ ìœ„í•´ ì±„ë„ ë³€í™˜
    x = Conv2D(3, (1, 1), activation="relu")(x)

    # EfficientNetB3 ë¶ˆëŸ¬ì˜¤ê¸° (ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©)
    base_model = EfficientNetB3(weights="imagenet", include_top=False, input_shape=(64, 64, 3))
    base_model.trainable = False  # ì´ˆê¸° ê°€ì¤‘ì¹˜ ë™ê²°

    # ì¼ë¶€ ë ˆì´ì–´ë§Œ í•™ìŠµ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
    for layer in base_model.layers[-20:]:  
        layer.trainable = True  # ë§ˆì§€ë§‰ 20ê°œ ë ˆì´ì–´ë§Œ í•™ìŠµ ê°€ëŠ¥

    # EfficientNetB3 ì ìš© (TimeDistributed í•„ìš” ì—†ìŒ)
    x = base_model(x)
    x = BatchNormalization()(x)
    x = GlobalAveragePooling2D()(x)

    # Fully Connected Layer
    x = Dense(512, activation="relu", kernel_regularizer=l2(0.01))(x)
    x = Dropout(0.3)(x)
    x = Dense(256, activation="relu", kernel_regularizer=l2(0.01))(x)
    x = Dropout(0.3)(x)
    x = Dense(128, activation="relu", kernel_regularizer=l2(0.01))(x)
    x = Dropout(0.3)(x)
    x = Dense(self.num_classes, activation="softmax")(x)

    model = Model(inputs=video_input, outputs=x)
    model.compile(optimizer='adam',
                  loss="categorical_crossentropy",
                  metrics=["accuracy"])
    return model


class CustomCheckpoint(Callback):
    """
    ì—í¬í¬ 20 ì´ìƒ & val_accuracy í–¥ìƒ ì‹œì—ë§Œ ëª¨ë¸ ì €ì¥
    """
    def __init__(self, save_dir="models"):
        super(CustomCheckpoint, self).__init__()
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)  # ì €ì¥ í´ë” ìƒì„±
        self.best_val_acc = 0  # ìµœê³  val_accuracy ì €ì¥

    def on_epoch_end(self, epoch, logs=None):
        if logs is None:
            return

        val_acc = logs.get("val_accuracy", 0)
        val_loss = logs.get("val_loss", 0)

        # ì—í¬í¬ê°€ 20 ì´ìƒ & val_accuracy í–¥ìƒ ì‹œ ì €ì¥
        if (epoch + 1 >= 20 and val_acc > self.best_val_acc) or (epoch + 1 >= 80 and val_acc > 70):
            self.best_val_acc = val_acc  # ìµœê³  val_accuracy ì—…ë°ì´íŠ¸

            # íŒŒì¼ëª…ì— epoch, val_acc, val_loss í¬í•¨
            filename = f"model_epoch-{epoch+1:03d}_val-acc-{val_acc:.4f}_val-loss-{val_loss:.4f}.h5"
            filepath = os.path.join(self.save_dir, filename)

            # ëª¨ë¸ ì €ì¥
            self.model.save(filepath)
            print(f"ëª¨ë¸ ì €ì¥ë¨: {filename}")


class Trainer:
    """
    ëª¨ë¸ í•™ìŠµ, í‰ê°€ ë° ì‹œê°í™”ë¥¼ ìœ„í•œ í´ë˜ìŠ¤
    """
    def __init__(self, model, train_X, train_y, test_X=None, test_y=None, batch_size=2, epochs=100, save_path="CNN_model/"):
        self.model = model
        self.train_X = train_X
        self.train_y = train_y
        self.test_X = test_X
        self.test_y = test_y
        self.batch_size = batch_size
        self.epochs = epochs
        self.save_path = save_path

    def train(self):
        # EarlyStopping ë° ReduceLROnPlateau ì ìš©
        checkpoint_callback = CustomCheckpoint(save_dir=self.save_path)
        reduce_lr = ReduceLROnPlateau(monitor='val_loss', # val_lossê¸°ì¤€
                                      factor=0.5, # ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµë¥  50í”„ë¡œ ê°ì†Œ
                                      patience=5, # 5ë²ˆë™ì•ˆ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµë¥  ê°ì†Œ
                                      min_lr=1e-6) # ê³¼ì í•©ì„ ì¤„ì´ê¸° ìœ„í•´ í•™ìŠµë¥  ì¡°ì ˆì ˆ

        hist = self.model.fit(
            self.train_X, self.train_y,
            validation_split=0.3,
            epochs=self.epochs,
            batch_size=self.batch_size,
            callbacks=[checkpoint_callback]
        )

        self.model.save("cnn_model.h5")
        self.plot_results(hist)

    def plot_results(self, hist):
        """ í•™ìŠµ ê³¡ì„  ì‹œê°í™” """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        fig, loss_ax = plt.subplots(figsize=(10, 5))
        loss_ax.plot(hist.history['loss'], 'r', label='train loss')
        loss_ax.plot(hist.history['val_loss'], 'y', label='validation loss')
        loss_ax.set_xlabel('epoch')
        loss_ax.set_ylabel('loss')

        acc_ax = loss_ax.twinx()
        acc_ax.plot(hist.history['accuracy'], 'b', label='train accuracy')
        acc_ax.plot(hist.history['val_accuracy'], 'g', label='validation accuracy')
        acc_ax.set_ylabel('accuracy')

        loss_ax.legend(loc="upper left", bbox_to_anchor=(0.02, 0.98))
        acc_ax.legend(loc="upper right", bbox_to_anchor=(0.98, 0.98))

        plt.savefig(f"{timestamp}_plot.jpg", dpi=300)
        plt.show()

    def evaluate(self):
        """ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ì˜ˆì¸¡ í›„ ì„±ëŠ¥ í‰ê°€ """
        if self.test_X is None or self.test_y is None:
            print("í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤! `test_X`ì™€ `test_y`ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ì˜ˆì¸¡ ìˆ˜í–‰
        y_pred_prob = self.model.predict(self.test_X)
        y_pred = np.argmax(y_pred_prob, axis=1)
        y_true = np.argmax(self.test_y, axis=1)

        # í˜¼ë™ í–‰ë ¬ (Confusion Matrix) ìƒì„±
        cm = confusion_matrix(y_true, y_pred)

        # Pandas DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ crosstab ì‹œê°í™”
        labels = list(range(self.test_y.shape[1]))  # í´ë˜ìŠ¤ ê°œìˆ˜
        cm_df = pd.DataFrame(cm, index=labels, columns=labels)

        plt.figure(figsize=(8, 6))
        sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')
        plt.xlabel("Predicted Label")
        plt.ylabel("True Label")
        plt.title("Confusion Matrix (Crosstab)")
        plt.savefig(f"{timestamp}_crosstab.jpg", dpi=300)
        plt.show()

        # í‰ê°€ ì§€í‘œ ê³„ì‚°
        f1 = f1_score(y_true, y_pred, average=None)  # í´ë˜ìŠ¤ë³„ F1 Score
        f1_macro = f1_score(y_true, y_pred, average="macro")  # ë§¤í¬ë¡œ í‰ê· 
        f1_weighted = f1_score(y_true, y_pred, average="weighted")  # ê°€ì¤‘ í‰ê· 
        precision = precision_score(y_true, y_pred, average="macro")  # Precision
        recall = recall_score(y_true, y_pred, average="macro")  # Recall
        accuracy = accuracy_score(y_true, y_pred)  # Accuracy

        # í‰ê°€ ì§€í‘œ ì¶œë ¥
        print("\n F1 Score (í´ë˜ìŠ¤ë³„):", f1)
        print(f" F1 Score (Macro í‰ê· ): {f1_macro:.4f}")
        print(f" F1 Score (Weighted í‰ê· ): {f1_weighted:.4f}")
        print(f" Precision (Macro í‰ê· ): {precision:.4f}")
        print(f" Recall (Macro í‰ê· ): {recall:.4f}")
        print(f" Accuracy: {accuracy:.4f}")

        # í˜„ì¬ ì‹œê°„ ê¸°ë°˜ íŒŒì¼ ì´ë¦„ ìƒì„±
        txt_filename = f"{timestamp}_CNN.txt"
        csv_filename = f"{timestamp}_crosstab.csv"

        # Confusion Matrix CSV ì €ì¥
        cm_df.to_csv(csv_filename, index=True)
        print(f" Confusion Matrix ì €ì¥ë¨: {csv_filename}")

        # í‰ê°€ ì§€í‘œ TXT íŒŒì¼ ì €ì¥
        with open(txt_filename, "w") as f:
            f.write(" ëª¨ë¸ í‰ê°€ ì§€í‘œ\n")
            f.write("=" * 30 + "\n")
            f.write(f" F1 Score (í´ë˜ìŠ¤ë³„): {f1.tolist()}\n")
            f.write(f" F1 Score (Macro í‰ê· ): {f1_macro:.4f}\n")
            f.write(f" F1 Score (Weighted í‰ê· ): {f1_weighted:.4f}\n")
            f.write(f" Precision (Macro í‰ê· ): {precision:.4f}\n")
            f.write(f" Recall (Macro í‰ê· ): {recall:.4f}\n")
            f.write(f" Accuracy: {accuracy:.4f}\n")
            f.write("=" * 30 + "\n")

        print(f"í‰ê°€ ì§€í‘œ ì €ì¥ë¨: {txt_filename}")



if __name__ == '__main__':
    base_dir = 'D:/KHH/team_project/json_data/'
    img_base_dir = 'D:/KHH/team_project/img/'
    dataset_loader = DatasetLoader(base_dir, img_base_dir, img_size=(64, 64), test_split=0.2)

    json_df = pd.concat([pd.read_csv(base_dir+file) for file in os.listdir(base_dir) if 'validation' not in file])

    # print(json_df)

    dataset_df = dataset_loader.stratified_sampling_and_split(json_df, 'type', 10)
    dataset_df['folder'] = dataset_df['img_key'].apply(lambda x: "/".join(x.split("/")[:4])).str.replace('/', '@')

    # print(dataset_df.columns)

    img_dataset, drop_index = dataset_loader.load_images(dataset_df['folder'], dataset_df['type'])
    dataset_df.drop(index=drop_index, inplace=True)

    print(img_dataset.shape)

    train_X, train_Y, test_X, test_Y, train_LABELS, test_LABELS = dataset_loader.split_data(img_dataset, dataset_df[['type']])
    print(train_Y)
    print('-----------------------------------------------------------')
    print(test_Y)

    model = ConvLSTM_NasNet_Model().build_model()

    trainer = Trainer(model=model, train_X=train_X, train_y=train_Y, test_X=test_X, test_y=test_Y,epochs=10)
    trainer.train()
    trainer.evaluate()