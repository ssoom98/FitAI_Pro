import os
import json
import pandas as pd
import tarfile
import shutil
import tensorflow as tf
import tensorflow_hub as hub
import cv2
import numpy as np
import re
from ultralytics import YOLO

class ImageProcessor:

    # ğŸ”¹ í´ë˜ìŠ¤ ë³€ìˆ˜ ì¶”ê°€
    m = (255, 0, 255)
    c = (0, 255, 255)
    y = (255, 255, 0)

    KEYPOINT_DICT = {
        'nose': 0, 'left_eye': 1, 'right_eye': 2, 'left_ear': 3, 'right_ear': 4,
        'left_shoulder': 5, 'right_shoulder': 6, 'left_elbow': 7, 'right_elbow': 8,
        'left_wrist': 9, 'right_wrist': 10, 'left_hip': 11, 'right_hip': 12,
        'left_knee': 13, 'right_knee': 14, 'left_ankle': 15, 'right_ankle': 16
    }

    KEYPOINT_EDGES = {
        (0, 1): m, (0, 2): c, (1, 3): m, (2, 4): c, (0, 5): m, (0, 6): c,
        (5, 7): m, (7, 9): m, (6, 8): c, (8, 10): c, (5, 6): y, (5, 11): m,
        (6, 12): c, (11, 12): y, (11, 13): m, (13, 15): m, (12, 14): c, (14, 16): c
    }

    # MoveNet ëª¨ë¸ ë¡œë“œ (í´ë˜ìŠ¤ ë³€ìˆ˜ë¡œ ìœ ì§€)
    module = hub.load("https://tfhub.dev/google/movenet/singlepose/thunder/4")
    movenet = module.signatures['serving_default']

    def __init__(self, model_path="yolov8n.pt"):
        self.model = YOLO(model_path)  # YOLOv8 ëª¨ë¸ ë¡œë“œ

    def json_to_dict(self, path):
        """JSON íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ í•„ìš”í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ"""
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)

        if 'frames' in data:
            dict_list = []

            for frame in data['frames']:
                for view_name, view_data in frame.items():
                    if 'img_key' in view_data:
                        dict_list.append({
                            'img_key': view_data['img_key'],
                            'type': data['type_info']['type'],
                            'workout': data['type_info']['exercise'],
                            'conditions': data['type_info']['conditions'],
                            'description': data['type_info']['description']
                        })

            return dict_list
        else:
            print(f"âš  'frames' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤ - {path}")
            return None

    def detect_pose(self, image):
        """MoveNetì„ ì‚¬ìš©í•˜ì—¬ í¬ì¦ˆ ê°ì§€"""
        input_image = tf.image.resize(image, [256, 256])
        input_image = tf.expand_dims(input_image, axis=0)
        input_image = tf.cast(input_image, dtype=tf.int32)

        # Run model inference
        outputs = self.movenet(input_image)  # ğŸ”¹ í´ë˜ìŠ¤ ë³€ìˆ˜ movenet ì‚¬ìš©
        keypoints = outputs['output_0'].numpy()

        return keypoints

    def resized_image(self, image):
        """ì´ë¯¸ì§€ë¥¼ 256x256 í¬ê¸°ë¡œ ì¡°ì •"""
        return cv2.resize(image, (256, 256))

    def detect_person_yolov8_square_crop(self, image_path, confidence_threshold=0.5):
        """YOLOv8ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ëŒì„ ê°ì§€í•˜ê³  ì •ì‚¬ê°í˜•ìœ¼ë¡œ í¬ë¡­í•˜ëŠ” í•¨ìˆ˜."""
        image = cv2.imread(image_path)
        if image is None:
            raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")

        H, W, _ = image.shape

        # ê°ì²´ íƒì§€ ìˆ˜í–‰
        results = self.model(image)[0]

        best_confidence = 0.0
        best_box = None

        for box in results.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            confidence = box.conf[0].item()
            class_id = int(box.cls[0].item())

            if class_id == 0 and confidence > confidence_threshold:
                if confidence > best_confidence:
                    best_confidence = confidence
                    best_box = (x1, y1, x2, y2)

        if best_box:
            x1, y1, x2, y2 = best_box
            w, h = x2 - x1, y2 - y1
            side = max(w, h)

            center_x = (x1 + x2) / 2
            center_y = (y1 + y2) / 2

            new_x1 = int(max(0, min(W - side, center_x - side / 2)))
            new_y1 = int(max(0, min(H - side, center_y - side / 2)))
            new_x2 = new_x1 + int(side)
            new_y2 = new_y1 + int(side)

            cropped_image = image[new_y1:new_y2, new_x1:new_x2]
            cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)
            return self.resized_image(cropped_image)
        else:
            print("ì‚¬ëŒì´ íƒì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

    def unziped_tar(self, path, save_path='E:/project_data/unziped_file/img_temp/'):
        with tarfile.open(path, "r", encoding="utf-8") as tar:
            tar.extractall(save_path)
        print('ì••ì¶•í•´ì œ ì™„ë£Œ')

    def remove_file(self, path):
        if os.path.exists(path):
            shutil.rmtree(path)  # í´ë” ë‚´ë¶€ê¹Œì§€ ì™„ì „íˆ ì‚­ì œ
            print("í´ë”ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
